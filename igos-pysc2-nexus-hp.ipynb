{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tensorboardX import SummaryWriter\n",
    "import tqdm\n",
    "import os\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "IntTensor = torch.cuda.IntTensor if use_cuda else torch.IntTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "unique_id = str(uuid.uuid4())\n",
    "\n",
    "plot = plt.figure()\n",
    "\n",
    "def weights_initialize(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        module.bias.data.fill_(0.01)\n",
    "        \n",
    "class _TransModel(nn.Module):\n",
    "    \"\"\" Model for DQN \"\"\"\n",
    "\n",
    "    def __init__(self, input_len, output_len):\n",
    "        super(_TransModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            torch.nn.Linear(input_len, 1024),\n",
    "            torch.nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1.apply(weights_initialize)\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            torch.nn.Linear(1024, 256),\n",
    "            # torch.nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2.apply(weights_initialize)\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(256, output_len)\n",
    "        )\n",
    "        self.output_layer.apply(weights_initialize)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.fc1(input)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "\n",
    "class TransModel():\n",
    "    def __init__(self, input_len, ouput_len, learning_rate = 0.0001):\n",
    "        self.model = _TransModel(input_len, ouput_len)\n",
    "        \n",
    "        if use_cuda:\n",
    "            print(\"Using GPU\")\n",
    "            self.model = self.model.cuda()\n",
    "        else:\n",
    "            print(\"Using CPU\")\n",
    "        self.steps = 0\n",
    "        # self.model = nn.DataParallel(self.model)\n",
    "        self.optimizer = Adam(self.model.parameters(), lr = learning_rate)\n",
    "        self.loss_fn = nn.MSELoss(reduction='mean')\n",
    "        \n",
    "        self.steps = 0\n",
    "        \n",
    "    def predict(self, input, steps, learning):\n",
    "        \n",
    "        output = self.model(input).squeeze(1)\n",
    "        #reward, next_state = output[0], output[1:]\n",
    "\n",
    "        return output\n",
    "\n",
    "    def predict_batch(self, input):\n",
    "        output = self.model(input)\n",
    "        #reward, next_state = output[:, 0], output[:, 1:]\n",
    "        return output\n",
    "\n",
    "    def fit(self, state, target_state):\n",
    "        loss = self.loss_fn(state, target_state)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.steps += 1\n",
    "        return loss\n",
    "    \n",
    "    def save(self):\n",
    "        file_path = '../models_mb/nexus-HP-transition-model-predict-4.pt'\n",
    "        torch.save(self.model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binHP(hp):\n",
    "    hp = hp * 2000 # Un-normalize\n",
    "    category = \"Null\"\n",
    "    if(hp < 0):\n",
    "        category = \"> 0\"\n",
    "    \n",
    "    if (hp >= 0 and hp <= 250):\n",
    "        category = \"0-250\"\n",
    "\n",
    "    if (hp >= 251 and hp <= 500):\n",
    "        category = \"251-500\"\n",
    "\n",
    "    if (hp >= 501 and hp <= 750):\n",
    "        category = \"501-750\"\n",
    "\n",
    "    if (hp >= 751 and hp <= 1000):\n",
    "        category = \"751-1000\"\n",
    "\n",
    "    if (hp >= 1001 and hp <= 1250):\n",
    "        category = \"1001-1250\"\n",
    "\n",
    "    if (hp >= 1251 and hp <= 1500):\n",
    "        category = \"1251-1500\"\n",
    "\n",
    "    if (hp >= 1501 and hp <= 1750):\n",
    "        category = \"1501-1750\"\n",
    "\n",
    "    if (hp >= 1751 and hp <= 2000):\n",
    "        category = \"1751-2000\"\n",
    "        \n",
    "    if (hp >= 2001):\n",
    "        category = \">= 2001\"\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_plot(x, y, fig, style = 'o'):\n",
    "    x = x * 2000\n",
    "    y = y * 2000\n",
    "    legend = [\n",
    "                \"Match line\",\n",
    "                \"Player 1 Top HP\",\n",
    "                \"Player 1 Bottom HP\",\n",
    "                \"Player 2 Top HP\",\n",
    "                \"Player 2 Bottom HP\",\n",
    "             ]\n",
    "    fig=plt.figure(figsize=(15, 15), dpi= 160, facecolor='w', edgecolor='k')\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_ylim([-100,2100])\n",
    "    ax.set_xlim([-100,2100])\n",
    "    ax.plot(list(range(-100, 2100)),list(range(-100,2100)), \"b--\", alpha=0.05)\n",
    "    for i in range(len(legend) - 1):\n",
    "        #plt.plot(x[:, i].view(-1).tolist(), y[:, i].view(-1).tolist(), style, s = 0.1)\n",
    "        ax.scatter(x[:, i].view(-1).tolist(), y[:, i].view(-1).tolist(),s = 0.5)\n",
    "\n",
    "    plt.title('Ground Truth - Predict of Units')\n",
    "    plt.legend(legend, bbox_to_anchor=(0, 1), loc='upper left', ncol=1)\n",
    "    plt.xlabel(\"Ground Truth\")\n",
    "    plt.ylabel(\"Predict\")\n",
    "    chartBox = ax.get_position()\n",
    "    ax.set_position([chartBox.x0, chartBox.y0, chartBox.width, chartBox.height])\n",
    "    ax.legend(legend, loc='center left', bbox_to_anchor=(1, 0.8), shadow=True, ncol=1)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68,)\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('data/test_dataset.pt')\n",
    "l = len(data)\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    data[i][1] = [ data[i][1][63] / 2000 , data[i][1][64] / 2000 , data[i][1][65] / 2000 , data[i][1][66] / 2000 ]\n",
    "    \n",
    "    data[i][0][1:4] = np.true_divide( data[i][0][1:4], 30) # Normalize P1 top buildings\n",
    "    data[i][0][4:7] = np.true_divide( data[i][0][4:7], 30) # Normalize P1 bottom buildings\n",
    "\n",
    "    data[i][0][8:11] = np.true_divide( data[i][0][8:11], 30) # Normalize P2 top buildings\n",
    "    data[i][0][11:14] = np.true_divide( data[i][0][11:14], 30) # Normalize P2 bottom buildings\n",
    "    \n",
    "    data[i][0][63] = data[i][0][63] / 2000 # Normalize P1 Top Nexus HP\n",
    "    data[i][0][64] = data[i][0][64] / 2000 # Normalize P2 Top Nexus HP\n",
    "    \n",
    "    data[i][0][65] = data[i][0][65] / 2000 # Normalize P1 Bottom Nexus HP\n",
    "    data[i][0][66] = data[i][0][66] / 2000 # Normalize P2 Bottom Nexus HP\n",
    "\n",
    "    data[i][0][0] = data[i][0][10] / 1500 # Normalize P1 Minerals\n",
    "    \n",
    "data = np.array(data)\n",
    "print(data[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "tmodel = TransModel(len(data[0][0]), len(data[0][1]))\n",
    "tmodel.model.load_state_dict(torch.load(\"./nexus-HP-transition-model-predict-4.pt\"))\n",
    "tmodel = tmodel.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  tensor([[0.4738, 0.6785, 0.4956, 0.7095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor(0.4738, device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Gradient:  (tensor([[ 0.0023, -0.0854, -0.1332, -0.1668, -0.1929, -0.1710, -0.0643,  0.0461,\n",
      "          0.0320,  0.0709,  0.0148, -0.0796,  0.0674, -0.0847, -0.0093,  0.0092,\n",
      "         -0.0245,  0.0121,  0.0111, -0.0264,  0.0027,  0.0062,  0.0037, -0.0247,\n",
      "         -0.0072, -0.0092, -0.0212, -0.0121,  0.1416, -0.0043,  0.0074,  0.0370,\n",
      "         -0.0289,  0.0116,  0.0270, -0.0485, -0.0054,  0.0162,  0.0504,  0.0264,\n",
      "          0.0265,  0.0466,  0.0024,  0.0316, -0.0017,  0.0036, -0.0074, -0.0273,\n",
      "          0.0052, -0.0708,  0.0122, -0.0113,  0.0158,  0.0532,  0.0111,  0.0060,\n",
      "         -0.0290,  0.0061,  0.0234, -0.0211,  0.0079, -0.0202, -0.0427,  0.8879,\n",
      "         -0.0022, -0.0649, -0.1011,  0.0042]], device='cuda:0'),)\n",
      "Gradient:  (tensor([[-8.2123e-03, -2.2469e-02, -6.8142e-02, -1.5530e-01, -7.7761e-02,\n",
      "         -1.5044e-02, -1.8576e-01, -8.1751e-03,  2.0211e-02,  9.0982e-02,\n",
      "         -1.5140e-01, -1.8061e-01,  7.5344e-02, -1.7517e-01,  6.6387e-03,\n",
      "          1.5154e-02, -2.9927e-02,  2.7831e-02,  9.4739e-03, -7.8472e-03,\n",
      "          2.7215e-02,  1.9662e-04, -1.7952e-02,  2.4002e-02,  6.7280e-03,\n",
      "          1.7736e-02, -2.1907e-02,  1.5878e-02, -9.9431e-02,  1.1264e-01,\n",
      "          6.6670e-03, -4.9265e-02,  2.9426e-02,  1.9441e-03, -2.9746e-03,\n",
      "         -1.5402e-02, -1.2410e-03, -1.4240e-02,  3.4614e-02, -1.1908e-02,\n",
      "         -4.8480e-03, -2.6728e-02, -3.0349e-03,  3.1539e-02, -1.5654e-03,\n",
      "          6.3917e-03, -3.3007e-02, -3.5704e-03,  6.4901e-03,  1.4766e-02,\n",
      "          3.9906e-03,  4.8472e-02, -2.1979e-02,  6.3472e-03,  5.5203e-03,\n",
      "         -3.7474e-02, -1.6146e-02,  4.5437e-03, -1.6927e-02, -1.3306e-02,\n",
      "          1.0743e-02,  6.1127e-02, -6.0772e-03, -1.4496e-01,  8.6034e-01,\n",
      "         -1.9197e-02, -1.3580e-02,  5.5978e-03]], device='cuda:0'),)\n",
      "Gradient:  (tensor([[-4.2003e-03,  2.9532e-03,  1.3331e-01, -2.9853e-01, -8.5559e-02,\n",
      "         -2.4381e-01, -4.7069e-01, -5.5169e-02,  4.5695e-02,  8.1513e-02,\n",
      "         -4.0317e-02, -2.1340e-01,  1.3325e-01, -1.3140e-01, -4.8624e-02,\n",
      "          3.3488e-02, -3.9113e-03, -9.7025e-03,  7.6872e-03, -1.4381e-02,\n",
      "         -3.1111e-02,  1.2178e-02, -1.6595e-02, -9.1367e-03, -6.9619e-03,\n",
      "         -2.8815e-02, -6.0375e-02, -7.8843e-03,  1.4521e-01,  1.2094e-02,\n",
      "          1.4002e-02,  6.2516e-02, -5.1767e-02, -4.8624e-04,  2.7557e-02,\n",
      "         -1.1523e-02, -2.6378e-02, -1.1790e-02, -4.7766e-02, -4.0786e-02,\n",
      "         -2.2472e-02, -1.1191e-01, -1.0942e-02, -1.6362e-02,  2.9417e-02,\n",
      "          5.2202e-03, -5.5931e-02,  6.5406e-03, -1.5205e-03, -2.1723e-01,\n",
      "         -7.6226e-04, -1.9414e-02,  1.8599e-03,  4.0800e-02,  2.8985e-03,\n",
      "          1.7153e-02, -2.9899e-02,  4.5993e-03,  7.9699e-02, -4.5117e-02,\n",
      "          1.1105e-02,  9.4672e-02, -4.6290e-03, -7.5218e-02,  7.6451e-02,\n",
      "          7.9265e-01,  7.7152e-02, -1.0219e-04]], device='cuda:0'),)\n",
      "Gradient:  (tensor([[ 7.8377e-03, -5.6920e-02, -4.0559e-02, -1.6682e-01, -4.2190e-02,\n",
      "          2.4824e-02, -2.3053e-01,  9.2092e-03,  2.4195e-02,  1.4419e-01,\n",
      "         -1.3368e-02, -1.5231e-01,  6.1567e-02,  6.8084e-03, -1.5938e-02,\n",
      "          1.2246e-02, -4.6956e-02,  3.5507e-03,  7.6872e-03, -2.0117e-03,\n",
      "         -7.1785e-03,  5.3586e-03,  4.1600e-03, -4.9904e-03, -5.0304e-03,\n",
      "         -1.0165e-02, -4.3194e-02,  2.7114e-04,  4.4394e-02,  3.8790e-03,\n",
      "          8.9806e-03,  3.9543e-02, -8.1430e-04,  1.1929e-02,  3.1608e-02,\n",
      "         -4.3526e-04,  9.4379e-03,  8.6835e-03, -1.0449e-02, -2.1837e-02,\n",
      "          4.7875e-03, -8.8157e-03,  3.3989e-03, -1.9584e-02,  9.0005e-03,\n",
      "          6.1562e-03, -1.1725e-02, -1.5334e-02,  5.2587e-03, -5.4878e-02,\n",
      "          1.5092e-02, -1.0188e-02,  1.4349e-02,  2.8538e-02,  1.1753e-03,\n",
      "          2.8040e-03, -4.9599e-03,  4.3299e-04,  2.2697e-02, -1.3384e-02,\n",
      "         -4.1283e-03, -1.3512e-02, -4.3200e-02, -1.7695e-01,  7.2590e-02,\n",
      "          8.3253e-02,  7.9338e-01, -1.6388e-03]], device='cuda:0'),)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(np.stack(data[0, 0]), requires_grad=True).type(FloatTensor).view(1,68) # Input\n",
    "result = tmodel(x) # HP result from the tmodel\n",
    "\n",
    "print(\"Result: \", result)\n",
    "print(result[0][0])\n",
    "#print(\"Gradient: \", torch.autograd.grad(result.sum(), x, retain_graph=True))\n",
    "print(\"Gradient: \", torch.autograd.grad(result[0][0], x, retain_graph=True))\n",
    "print(\"Gradient: \", torch.autograd.grad(result[0][1], x, retain_graph=True))\n",
    "print(\"Gradient: \", torch.autograd.grad(result[0][2], x, retain_graph=True))\n",
    "print(\"Gradient: \", torch.autograd.grad(result[0][3], x, retain_graph=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
